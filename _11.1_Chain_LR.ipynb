{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu cores found: 64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "from helper_functions import *\n",
    "print(\"Cpu cores found:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/train.csv.zip\")\n",
    "test_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/test.csv.zip\")\n",
    "test_labels_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/test_labels.csv.zip\")\n",
    "sample_sub_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/sample_submission.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_full = pd.read_csv(train_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_classes = list(train_df_full.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = pd.read_csv(test_labels_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df = pd.read_csv(sample_sub_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classes = list(sample_sub_df.columns[1:])\n",
    "comments_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP1(text):\n",
    "    text_tok = word_tokenize(text)\n",
    "    \n",
    "    eng_stopwords = stopwords.words('english')\n",
    "    text_stp = [word for word in text_tok if (word.lower() not in eng_stopwords) and word.isalpha()]\n",
    "    \n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    text_stm = [stemmer.stem(word) for word in text_stp]\n",
    "    return text_stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000 # or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# eng_stopwords = stopwords.words('english')\n",
    "\n",
    "# vectorizer = TfidfVectorizer(lowercase=True, \n",
    "#                                tokenizer=NLP1,\n",
    "#                                stop_words=eng_stopwords,\n",
    "#                                ngram_range=(1,2),\n",
    "#                                max_features=max_features).fit(train_df_full.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, val_df = train_test_split(train_df_full, test_size=0.3, random_state=43)\n",
    "# train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_full = vectorizer.transform(train_df.comment_text)\n",
    "# x_val_full = vectorizer.transform(val_df.comment_text)\n",
    "# x_test_full = vectorizer.transform(test_df.comment_text)\n",
    "\n",
    "# y_train_full = train_df[comments_classes].to_numpy()\n",
    "# y_val_full = val_df[comments_classes].to_numpy()\n",
    "\n",
    "# x_train_full.shape, y_train_full.shape, x_val_full.shape, y_val_full.shape, x_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(x_train_full, f'x_train_full_{max_features}.joblib')\n",
    "# joblib.dump(x_val_full, f'x_val_full_{max_features}.joblib')\n",
    "# joblib.dump(x_test_full, f'x_test_full_{max_features}.joblib')\n",
    "\n",
    "# joblib.dump(y_train_full, f'y_train_full_{max_features}.joblib')\n",
    "# joblib.dump(y_val_full, f'y_val_full_{max_features}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((111699, 5000), (111699, 6), (47872, 5000), (47872, 6), (153164, 5000))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full = joblib.load(f'x_train_full_{max_features}.joblib')\n",
    "x_val_full = joblib.load(f'x_val_full_{max_features}.joblib')\n",
    "x_test_full = joblib.load(f'x_test_full_{max_features}.joblib')\n",
    "\n",
    "y_train_full = joblib.load(f'y_train_full_{max_features}.joblib')\n",
    "y_val_full = joblib.load(f'y_val_full_{max_features}.joblib')\n",
    "\n",
    "x_train_full.shape, y_train_full.shape, x_val_full.shape, y_val_full.shape, x_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_MChain_L2LR.csv\n",
      "head sub_MChain_L2LR.csv\n",
      "kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f sub_MChain_L2LR.csv -m \"Manual Chain 5000\"\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MChain_L2LR'\n",
    "SUB_CSV_NAME = f\"sub_{MODEL_NAME}.csv\"\n",
    "SUB_CSV_MSG = f\"Manual Chain\"\n",
    "\n",
    "cmd1 = f\"head {SUB_CSV_NAME}\"\n",
    "cmd2 = f'kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f {SUB_CSV_NAME} -m \"{SUB_CSV_MSG} {max_features}\"'\n",
    "print(SUB_CSV_NAME)\n",
    "print(cmd1)\n",
    "print(cmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 0 toxic ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_L2LR model on toxic column...\n",
      "Train ROC: 0.8184440033650753\n",
      "Val ROC: 0.8067855065493116\n",
      "Train Acc: 0.9605099418974208\n",
      "Val Acc: 0.9576161430481284\n",
      "test_prob: (153164, 2)\n",
      "******************** 1 severe_toxic ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_L2LR model on severe_toxic column...\n",
      "Train ROC: 0.5950198187701174\n",
      "Val ROC: 0.5764337461863432\n",
      "Train Acc: 0.9907698367935255\n",
      "Val Acc: 0.9897225935828877\n",
      "test_prob: (153164, 2)\n",
      "******************** 2 obscene ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_L2LR model on obscene column...\n",
      "Train ROC: 0.8733696320033274\n",
      "Val ROC: 0.8534946685325493\n",
      "Train Acc: 0.9822469314855101\n",
      "Val Acc: 0.9791945187165776\n",
      "test_prob: (153164, 2)\n",
      "******************** 3 threat ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_L2LR model on threat column...\n",
      "Train ROC: 0.5696116676829442\n",
      "Val ROC: 0.5336475839681774\n",
      "Train Acc: 0.9972873526173018\n",
      "Val Acc: 0.9968457553475936\n",
      "test_prob: (153164, 2)\n",
      "******************** 4 insult ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_L2LR model on insult column...\n",
      "Train ROC: 0.8283126932513981\n",
      "Val ROC: 0.8109031558660564\n",
      "Train Acc: 0.9753354998701869\n",
      "Val Acc: 0.9717371323529411\n",
      "test_prob: (153164, 2)\n",
      "******************** 5 identity_hate ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_L2LR model on identity_hate column...\n",
      "Train ROC: 0.6320858257470743\n",
      "Val ROC: 0.6357321386013058\n",
      "Train Acc: 0.9926946525931297\n",
      "Val Acc: 0.9932319518716578\n",
      "test_prob: (153164, 2)\n",
      "test_probs: (2, 153164, 6)\n",
      "CPU times: user 11 s, sys: 4.99 s, total: 16 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', penalty='l2', max_iter=1000, random_state=42, n_jobs=-1, tol=1e-5)\n",
    "x_train = lil_matrix(np.concatenate((x_train_full.toarray(), np.zeros_like(y_train_full)), axis=1))\n",
    "x_val = lil_matrix(np.concatenate((x_val_full.toarray(), np.zeros_like(y_val_full)), axis=1))\n",
    "x_test = lil_matrix(np.concatenate((x_test_full.toarray(), np.zeros((x_test_full.shape[0],6))), axis=1))\n",
    "test_probs = []\n",
    "\n",
    "for i, class_ in enumerate(comments_classes):\n",
    "    print('*'*20, i, class_, '*'*20)\n",
    "    \n",
    "    y_train, y_val = y_train_full[:,i], y_val_full[:,i]\n",
    "    print(\"x_train:\", x_train.shape)\n",
    "    print(\"x_val:\", x_val.shape)\n",
    "    print(\"x_test:\", x_test.shape)\n",
    "    print(\"y_train:\", y_train.shape)\n",
    "    print(\"y_val:\", y_val.shape)\n",
    "    \n",
    "    print(f'Fitting {MODEL_NAME} model on {class_} column...')\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(x_train)\n",
    "    val_pred = clf.predict(x_val)\n",
    "    test_pred = clf.predict(x_test)\n",
    "    test_prob = clf.predict_proba(x_test)\n",
    "    print(\"Train ROC:\", roc_auc_score(y_train,train_pred))\n",
    "    print(\"Val ROC:\", roc_auc_score(y_val,val_pred))\n",
    "    print(\"Train Acc:\", accuracy_score(y_train, train_pred))\n",
    "    print(\"Val Acc:\", accuracy_score(y_val, val_pred))\n",
    "    \n",
    "    x_train[:,5000+i] = train_pred\n",
    "    x_val[:,5000+i] = val_pred\n",
    "    x_test[:,5000+i] = test_pred\n",
    "    print('test_prob:', test_prob.shape)\n",
    "    test_probs.append(test_prob)\n",
    "    \n",
    "test_probs = np.array(test_probs).T\n",
    "print(\"test_probs:\", test_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 153164, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.52235094e-04, 7.60889330e-01, 6.31458540e-03, 9.25630127e-01,\n",
       "         5.16348652e-02, 4.92169502e-01],\n",
       "        [9.90420040e-01, 9.99370873e-01, 9.95339076e-01, 9.99169203e-01,\n",
       "         9.89349958e-01, 9.98110980e-01],\n",
       "        [9.88310292e-01, 9.99621989e-01, 9.96020340e-01, 9.99633512e-01,\n",
       "         9.94997966e-01, 9.99124884e-01],\n",
       "        ...,\n",
       "        [9.94689949e-01, 9.99457547e-01, 9.94678861e-01, 9.99337991e-01,\n",
       "         9.95330716e-01, 9.98323725e-01],\n",
       "        [9.71533845e-01, 9.99273166e-01, 9.85540447e-01, 9.99057748e-01,\n",
       "         9.85296010e-01, 9.91818335e-01],\n",
       "        [9.00463440e-02, 9.90471487e-01, 3.25265716e-01, 9.82035372e-01,\n",
       "         4.75345891e-01, 9.56291268e-01]]),\n",
       " array([[9.99347765e-01, 2.39110670e-01, 9.93685415e-01, 7.43698726e-02,\n",
       "         9.48365135e-01, 5.07830498e-01],\n",
       "        [9.57995953e-03, 6.29126769e-04, 4.66092373e-03, 8.30796639e-04,\n",
       "         1.06500421e-02, 1.88901972e-03],\n",
       "        [1.16897081e-02, 3.78011017e-04, 3.97965965e-03, 3.66487941e-04,\n",
       "         5.00203448e-03, 8.75116461e-04],\n",
       "        ...,\n",
       "        [5.31005104e-03, 5.42452514e-04, 5.32113871e-03, 6.62009104e-04,\n",
       "         4.66928382e-03, 1.67627549e-03],\n",
       "        [2.84661553e-02, 7.26833847e-04, 1.44595529e-02, 9.42252100e-04,\n",
       "         1.47039901e-02, 8.18166468e-03],\n",
       "        [9.09953656e-01, 9.52851262e-03, 6.74734284e-01, 1.79646284e-02,\n",
       "         5.24654109e-01, 4.37087321e-02]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs[0], test_probs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.loc[:, comments_classes] = test_probs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.239111</td>\n",
       "      <td>0.993685</td>\n",
       "      <td>0.074370</td>\n",
       "      <td>0.948365</td>\n",
       "      <td>0.507830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.011298</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.060850</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.001676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.014704</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.909954</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.674734</td>\n",
       "      <td>0.017965</td>\n",
       "      <td>0.524654</td>\n",
       "      <td>0.043709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "0       00001cee341fdb12  0.999348      0.239111  0.993685  0.074370   \n",
       "1       0000247867823ef7  0.009580      0.000629  0.004661  0.000831   \n",
       "2       00013b17ad220c46  0.011690      0.000378  0.003980  0.000366   \n",
       "3       00017563c3f7919a  0.008143      0.000679  0.003350  0.000682   \n",
       "4       00017695ad8997eb  0.035249      0.000491  0.011298  0.000491   \n",
       "...                  ...       ...           ...       ...       ...   \n",
       "153159  fffcd0960ee309b5  0.060850      0.000297  0.005684  0.000562   \n",
       "153160  fffd7a9a6eb32c16  0.157200      0.000660  0.011682  0.002037   \n",
       "153161  fffda9e8d6fafa9e  0.005310      0.000542  0.005321  0.000662   \n",
       "153162  fffe8f1340a79fc2  0.028466      0.000727  0.014460  0.000942   \n",
       "153163  ffffce3fb183ee80  0.909954      0.009529  0.674734  0.017965   \n",
       "\n",
       "          insult  identity_hate  \n",
       "0       0.948365       0.507830  \n",
       "1       0.010650       0.001889  \n",
       "2       0.005002       0.000875  \n",
       "3       0.004379       0.000835  \n",
       "4       0.014144       0.001389  \n",
       "...          ...            ...  \n",
       "153159  0.019215       0.002302  \n",
       "153160  0.023762       0.003145  \n",
       "153161  0.004669       0.001676  \n",
       "153162  0.014704       0.008182  \n",
       "153163  0.524654       0.043709  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
      "00001cee341fdb12,0.9993477649055471,0.23911066978059017,0.9936854145983333,0.07436987263907294,0.9483651347531701,0.5078304983296601\n",
      "0000247867823ef7,0.009579959534427087,0.0006291267693257473,0.004660923727601092,0.0008307966386802035,0.010650042098591137,0.0018890197173846706\n",
      "00013b17ad220c46,0.011689708145305363,0.00037801101715612226,0.003979659645261072,0.00036648794071602914,0.0050020344758732755,0.0008751164614980881\n",
      "00017563c3f7919a,0.008142734293110354,0.000678927375874587,0.003350131282855457,0.000682414180625841,0.004379246417651049,0.000834902797665698\n",
      "00017695ad8997eb,0.03524865263551584,0.0004914661351086814,0.011297527974774343,0.0004911124190749183,0.014144131959514708,0.0013885117638588083\n",
      "0001ea8717f6de06,0.00630672997374889,0.0002873472798044377,0.0023388584451227647,0.00046071744575829754,0.004605945667397367,0.000787349648005488\n",
      "00024115d4cbde0f,0.008862859579603382,0.00022011128751434222,0.005726911123344755,0.0003977011010840714,0.005907995681952006,0.000955115617638511\n",
      "000247e83dcc1211,0.4824273505159943,0.0004650912690107139,0.012984256324499297,0.0011475145891268082,0.03248474549050216,0.003725301739882205\n",
      "00025358d4737918,0.02817990151917754,0.0005844020684075363,0.009973014128556685,0.0008223013065529737,0.004897669096736977,0.002081153378784137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='head sub_MChain_L2LR.csv', returncode=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df.to_csv(SUB_CSV_NAME, index=False)\n",
    "subprocess.run(cmd1, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21.0M/21.0M [00:09<00:00, 2.30MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Toxic Comment Classification Challenge"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f sub_MChain_L2LR.csv -m \"Manual Chain 5000\"', returncode=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(cmd2, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
