{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu cores found: 64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import copy\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "from helper_functions import *\n",
    "print(\"Cpu cores found:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/train.csv.zip\")\n",
    "test_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/test.csv.zip\")\n",
    "test_labels_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/test_labels.csv.zip\")\n",
    "sample_sub_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/sample_submission.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_full = pd.read_csv(train_fname)\n",
    "# test_df = pd.read_csv(test_fname)\n",
    "# test_labels = pd.read_csv(test_labels_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df = pd.read_csv(sample_sub_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classes = list(sample_sub_df.columns[1:])\n",
    "comments_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP1(text):\n",
    "    text_tok = word_tokenize(text)\n",
    "    \n",
    "    eng_stopwords = stopwords.words('english')\n",
    "    text_stp = [word for word in text_tok if (word.lower() not in eng_stopwords) and word.isalpha()]\n",
    "    \n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    text_stm = [stemmer.stem(word) for word in text_stp]\n",
    "    return text_stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000 # or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# eng_stopwords = stopwords.words('english')\n",
    "\n",
    "# vectorizer = TfidfVectorizer(lowercase=True, \n",
    "#                                tokenizer=NLP1,\n",
    "#                                stop_words=eng_stopwords,\n",
    "#                                ngram_range=(1,2),\n",
    "#                                max_features=max_features).fit(train_df_full.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, val_df = train_test_split(train_df_full, test_size=0.3, random_state=43)\n",
    "# train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_full = vectorizer.transform(train_df.comment_text)\n",
    "# x_val_full = vectorizer.transform(val_df.comment_text)\n",
    "# x_test_full = vectorizer.transform(test_df.comment_text)\n",
    "\n",
    "# y_train_full = train_df[comments_classes].to_numpy()\n",
    "# y_val_full = val_df[comments_classes].to_numpy()\n",
    "\n",
    "# x_train_full.shape, y_train_full.shape, x_val_full.shape, y_val_full.shape, x_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(x_train_full, f'x_train_full_{max_features}.joblib')\n",
    "# joblib.dump(x_val_full, f'x_val_full_{max_features}.joblib')\n",
    "# joblib.dump(x_test_full, f'x_test_full_{max_features}.joblib')\n",
    "\n",
    "# joblib.dump(y_train_full, f'y_train_full_{max_features}.joblib')\n",
    "# joblib.dump(y_val_full, f'y_val_full_{max_features}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((111699, 5000), (111699, 6), (47872, 5000), (47872, 6), (153164, 5000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full = joblib.load(f'x_train_full_{max_features}.joblib')\n",
    "x_val_full = joblib.load(f'x_val_full_{max_features}.joblib')\n",
    "x_test_full = joblib.load(f'x_test_full_{max_features}.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_full = joblib.load(f'y_train_full_{max_features}.joblib')\n",
    "y_val_full = joblib.load(f'y_val_full_{max_features}.joblib')\n",
    "\n",
    "x_train_full.shape, y_train_full.shape, x_val_full.shape, y_val_full.shape, x_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_MChain_MLP.csv\n",
      "head sub_MChain_MLP.csv\n",
      "kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f sub_MChain_MLP.csv -m \"Manual Chain 5000\"\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MChain_MLP'\n",
    "SUB_CSV_NAME = f\"sub_{MODEL_NAME}.csv\"\n",
    "SUB_CSV_MSG = f\"Manual Chain\"\n",
    "\n",
    "cmd1 = f\"head {SUB_CSV_NAME}\"\n",
    "cmd2 = f'kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f {SUB_CSV_NAME} -m \"{SUB_CSV_MSG} {max_features}\"'\n",
    "print(SUB_CSV_NAME)\n",
    "print(cmd1)\n",
    "print(cmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 0 toxic ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_MLP model on toxic column...\n",
      "Iteration 1, loss = 0.15818402\n",
      "Validation score: 0.956312\n",
      "Iteration 2, loss = 0.10820200\n",
      "Validation score: 0.957207\n",
      "Iteration 3, loss = 0.07875170\n",
      "Validation score: 0.956222\n",
      "Iteration 4, loss = 0.03986062\n",
      "Validation score: 0.951567\n",
      "Iteration 5, loss = 0.02606242\n",
      "Validation score: 0.953894\n",
      "Iteration 6, loss = 0.02157589\n",
      "Validation score: 0.954432\n",
      "Iteration 7, loss = 0.01986923\n",
      "Validation score: 0.955416\n",
      "Iteration 8, loss = 0.02174548\n",
      "Validation score: 0.948702\n",
      "Iteration 9, loss = 0.02081444\n",
      "Validation score: 0.952462\n",
      "Iteration 10, loss = 0.01952162\n",
      "Validation score: 0.948523\n",
      "Iteration 11, loss = 0.01782561\n",
      "Validation score: 0.948791\n",
      "Iteration 12, loss = 0.01731503\n",
      "Validation score: 0.953357\n",
      "Iteration 13, loss = 0.01777675\n",
      "Validation score: 0.951388\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "4 minutes 45.28 seconds\n",
      "Train ROC: 0.8878669763790334\n",
      "Val ROC: 0.8287857577051452\n",
      "Train Acc: 0.97414479986392\n",
      "Val Acc: 0.9572401403743316\n",
      "test_prob: (153164, 2)\n",
      "******************** 1 severe_toxic ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_MLP model on severe_toxic column...\n",
      "Iteration 1, loss = 0.03846595\n",
      "Validation score: 0.990152\n",
      "Iteration 2, loss = 0.02417370\n",
      "Validation score: 0.990421\n",
      "Iteration 3, loss = 0.02051012\n",
      "Validation score: 0.990510\n",
      "Iteration 4, loss = 0.01630894\n",
      "Validation score: 0.989078\n",
      "Iteration 5, loss = 0.01247077\n",
      "Validation score: 0.988630\n",
      "Iteration 6, loss = 0.01018364\n",
      "Validation score: 0.989705\n",
      "Iteration 7, loss = 0.00850854\n",
      "Validation score: 0.986482\n",
      "Iteration 8, loss = 0.00798764\n",
      "Validation score: 0.986929\n",
      "Iteration 9, loss = 0.00716756\n",
      "Validation score: 0.988362\n",
      "Iteration 10, loss = 0.00679531\n",
      "Validation score: 0.987825\n",
      "Iteration 11, loss = 0.00770429\n",
      "Validation score: 0.989346\n",
      "Iteration 12, loss = 0.00666739\n",
      "Validation score: 0.987735\n",
      "Iteration 13, loss = 0.00624086\n",
      "Validation score: 0.987914\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "4 minutes 58.05 seconds\n",
      "Train ROC: 0.7081605354153496\n",
      "Val ROC: 0.5845321685593386\n",
      "Train Acc: 0.9935272473343539\n",
      "Val Acc: 0.9898270387700535\n",
      "test_prob: (153164, 2)\n",
      "******************** 2 obscene ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_MLP model on obscene column...\n",
      "Iteration 1, loss = 0.08252715\n",
      "Validation score: 0.980842\n",
      "Iteration 2, loss = 0.05449277\n",
      "Validation score: 0.980483\n",
      "Iteration 3, loss = 0.04164312\n",
      "Validation score: 0.979588\n",
      "Iteration 4, loss = 0.02945663\n",
      "Validation score: 0.979141\n",
      "Iteration 5, loss = 0.02001903\n",
      "Validation score: 0.977798\n",
      "Iteration 6, loss = 0.01603874\n",
      "Validation score: 0.980036\n",
      "Iteration 7, loss = 0.01413873\n",
      "Validation score: 0.979409\n",
      "Iteration 8, loss = 0.01377162\n",
      "Validation score: 0.978066\n",
      "Iteration 9, loss = 0.01335177\n",
      "Validation score: 0.977440\n",
      "Iteration 10, loss = 0.01200536\n",
      "Validation score: 0.979051\n",
      "Iteration 11, loss = 0.01031037\n",
      "Validation score: 0.977529\n",
      "Iteration 12, loss = 0.01143633\n",
      "Validation score: 0.978782\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "4 minutes 28.21 seconds\n",
      "Train ROC: 0.8848126931911635\n",
      "Val ROC: 0.839810582208918\n",
      "Train Acc: 0.9844045157073922\n",
      "Val Acc: 0.9782754010695187\n",
      "test_prob: (153164, 2)\n",
      "******************** 3 threat ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_MLP model on threat column...\n",
      "Iteration 1, loss = 0.02403200\n",
      "Validation score: 0.997046\n",
      "Iteration 2, loss = 0.00979182\n",
      "Validation score: 0.997225\n",
      "Iteration 3, loss = 0.00713296\n",
      "Validation score: 0.997135\n",
      "Iteration 4, loss = 0.00562317\n",
      "Validation score: 0.996598\n",
      "Iteration 5, loss = 0.00454232\n",
      "Validation score: 0.995882\n",
      "Iteration 6, loss = 0.00401289\n",
      "Validation score: 0.997135\n",
      "Iteration 7, loss = 0.00336376\n",
      "Validation score: 0.997225\n",
      "Iteration 8, loss = 0.00284323\n",
      "Validation score: 0.997135\n",
      "Iteration 9, loss = 0.00307325\n",
      "Validation score: 0.995524\n",
      "Iteration 10, loss = 0.00268275\n",
      "Validation score: 0.996240\n",
      "Iteration 11, loss = 0.00244636\n",
      "Validation score: 0.996240\n",
      "Iteration 12, loss = 0.00267824\n",
      "Validation score: 0.996867\n",
      "Iteration 13, loss = 0.00226786\n",
      "Validation score: 0.996240\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "4 minutes 47.03 seconds\n",
      "Train ROC: 0.7059304082497251\n",
      "Val ROC: 0.594364102598953\n",
      "Train Acc: 0.9980035631473871\n",
      "Val Acc: 0.997033756684492\n",
      "test_prob: (153164, 2)\n",
      "******************** 4 insult ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_MLP model on insult column...\n",
      "Iteration 1, loss = 0.09310652\n",
      "Validation score: 0.970725\n",
      "Iteration 2, loss = 0.07030361\n",
      "Validation score: 0.970367\n",
      "Iteration 3, loss = 0.05665877\n",
      "Validation score: 0.968935\n",
      "Iteration 4, loss = 0.03761104\n",
      "Validation score: 0.967413\n",
      "Iteration 5, loss = 0.02573884\n",
      "Validation score: 0.966338\n",
      "Iteration 6, loss = 0.01908564\n",
      "Validation score: 0.967413\n",
      "Iteration 7, loss = 0.01633440\n",
      "Validation score: 0.967413\n",
      "Iteration 8, loss = 0.01642829\n",
      "Validation score: 0.966517\n",
      "Iteration 9, loss = 0.01642731\n",
      "Validation score: 0.966249\n",
      "Iteration 10, loss = 0.01496805\n",
      "Validation score: 0.965533\n",
      "Iteration 11, loss = 0.01431296\n",
      "Validation score: 0.964637\n",
      "Iteration 12, loss = 0.01393937\n",
      "Validation score: 0.964637\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "4 minutes 35.28 seconds\n",
      "Train ROC: 0.851672731603909\n",
      "Val ROC: 0.8140730500528139\n",
      "Train Acc: 0.9766873472457229\n",
      "Val Acc: 0.9705464572192514\n",
      "test_prob: (153164, 2)\n",
      "******************** 5 identity_hate ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_MLP model on identity_hate column...\n",
      "Iteration 1, loss = 0.04185367\n",
      "Validation score: 0.991674\n",
      "Iteration 2, loss = 0.02414208\n",
      "Validation score: 0.992390\n",
      "Iteration 3, loss = 0.01846503\n",
      "Validation score: 0.991137\n",
      "Iteration 4, loss = 0.01410184\n",
      "Validation score: 0.990331\n",
      "Iteration 5, loss = 0.01110453\n",
      "Validation score: 0.991316\n",
      "Iteration 6, loss = 0.00906850\n",
      "Validation score: 0.988183\n",
      "Iteration 7, loss = 0.00814784\n",
      "Validation score: 0.989526\n",
      "Iteration 8, loss = 0.00771251\n",
      "Validation score: 0.991137\n",
      "Iteration 9, loss = 0.00655299\n",
      "Validation score: 0.990868\n",
      "Iteration 10, loss = 0.00658866\n",
      "Validation score: 0.990868\n",
      "Iteration 11, loss = 0.00627141\n",
      "Validation score: 0.991495\n",
      "Iteration 12, loss = 0.00613618\n",
      "Validation score: 0.990063\n",
      "Iteration 13, loss = 0.00511042\n",
      "Validation score: 0.990868\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "5 minutes 0.99 seconds\n",
      "Train ROC: 0.7047459049412953\n",
      "Val ROC: 0.6497059875996068\n",
      "Train Acc: 0.994073357863544\n",
      "Val Acc: 0.9934199532085561\n",
      "test_prob: (153164, 2)\n",
      "test_probs: (2, 153164, 6)\n",
      "CPU times: user 14h 49min 54s, sys: 29min 32s, total: 15h 19min 26s\n",
      "Wall time: 29min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512,256,128), activation=\"relu\", \n",
    "                    solver=\"adam\", alpha = 0.001, batch_size=128, learning_rate = \"constant\",\n",
    "                    max_iter=1000, early_stopping=True,\n",
    "                    random_state=42, verbose=1)\n",
    "x_train = lil_matrix(np.concatenate((x_train_full.toarray(), np.zeros_like(y_train_full)), axis=1))\n",
    "x_val = lil_matrix(np.concatenate((x_val_full.toarray(), np.zeros_like(y_val_full)), axis=1))\n",
    "x_test = lil_matrix(np.concatenate((x_test_full.toarray(), np.zeros((x_test_full.shape[0],6))), axis=1))\n",
    "test_probs = []\n",
    "\n",
    "for i, class_ in enumerate(comments_classes):\n",
    "    print('*'*20, i, class_, '*'*20)\n",
    "    \n",
    "    y_train, y_val = y_train_full[:,i], y_val_full[:,i]\n",
    "    print(\"x_train:\", x_train.shape)\n",
    "    print(\"x_val:\", x_val.shape)\n",
    "    print(\"x_test:\", x_test.shape)\n",
    "    print(\"y_train:\", y_train.shape)\n",
    "    print(\"y_val:\", y_val.shape)\n",
    "    \n",
    "    t = timer()\n",
    "    print(f'Fitting {MODEL_NAME} model on {class_} column...')\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(format_time(t,timer()))\n",
    "    \n",
    "    train_pred = clf.predict(x_train)\n",
    "    val_pred = clf.predict(x_val)\n",
    "    test_pred = clf.predict(x_test)\n",
    "    test_prob = clf.predict_proba(x_test)\n",
    "    print(\"Train ROC:\", roc_auc_score(y_train,train_pred))\n",
    "    print(\"Val ROC:\", roc_auc_score(y_val,val_pred))\n",
    "    print(\"Train Acc:\", accuracy_score(y_train, train_pred))\n",
    "    print(\"Val Acc:\", accuracy_score(y_val, val_pred))\n",
    "    \n",
    "    x_train[:,5000+i] = train_pred\n",
    "    x_val[:,5000+i] = val_pred\n",
    "    x_test[:,5000+i] = test_pred\n",
    "    print('test_prob:', test_prob.shape)\n",
    "    test_probs.append(test_prob)\n",
    "    \n",
    "test_probs = np.array(test_probs).T\n",
    "print(\"test_probs:\", test_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 153164, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.loc[:, comments_classes] = test_probs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>1.890233e-01</td>\n",
       "      <td>0.926037</td>\n",
       "      <td>6.843566e-02</td>\n",
       "      <td>0.925951</td>\n",
       "      <td>0.195273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>5.830921e-06</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>3.837582e-05</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>2.265731e-06</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>4.140574e-07</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>2.418638e-06</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>1.916480e-06</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.019343</td>\n",
       "      <td>1.686708e-06</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>2.803807e-05</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>1.321449e-07</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>9.866458e-07</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.148956</td>\n",
       "      <td>3.218708e-06</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>1.522563e-03</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>4.919868e-06</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>5.017074e-06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>2.472550e-06</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>5.393663e-05</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.905387</td>\n",
       "      <td>1.033969e-05</td>\n",
       "      <td>0.377250</td>\n",
       "      <td>1.373816e-03</td>\n",
       "      <td>0.247922</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene        threat  \\\n",
       "0       00001cee341fdb12  0.999445  1.890233e-01  0.926037  6.843566e-02   \n",
       "1       0000247867823ef7  0.000104  5.830921e-06  0.000912  3.837582e-05   \n",
       "2       00013b17ad220c46  0.011046  2.265731e-06  0.004048  4.140574e-07   \n",
       "3       00017563c3f7919a  0.001394  2.418638e-06  0.001132  1.916480e-06   \n",
       "4       00017695ad8997eb  0.019343  1.686708e-06  0.019196  2.803807e-05   \n",
       "...                  ...       ...           ...       ...           ...   \n",
       "153159  fffcd0960ee309b5  0.026581  1.321449e-07  0.010192  9.866458e-07   \n",
       "153160  fffd7a9a6eb32c16  0.148956  3.218708e-06  0.010016  1.522563e-03   \n",
       "153161  fffda9e8d6fafa9e  0.000074  4.919868e-06  0.002450  5.017074e-06   \n",
       "153162  fffe8f1340a79fc2  0.002958  2.472550e-06  0.008415  5.393663e-05   \n",
       "153163  ffffce3fb183ee80  0.905387  1.033969e-05  0.377250  1.373816e-03   \n",
       "\n",
       "          insult  identity_hate  \n",
       "0       0.925951       0.195273  \n",
       "1       0.002805       0.000051  \n",
       "2       0.003013       0.000186  \n",
       "3       0.000241       0.000011  \n",
       "4       0.011620       0.000133  \n",
       "...          ...            ...  \n",
       "153159  0.002290       0.000011  \n",
       "153160  0.007031       0.000845  \n",
       "153161  0.000169       0.000091  \n",
       "153162  0.002281       0.002143  \n",
       "153163  0.247922       0.002619  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
      "00001cee341fdb12,0.9994453322563468,0.18902329686979952,0.9260369917257686,0.06843565781470484,0.9259510193429243,0.1952726405140076\n",
      "0000247867823ef7,0.00010376301991249772,5.830921002787536e-06,0.0009122053529318921,3.8375817338616084e-05,0.0028054953264986704,5.1018790807783026e-05\n",
      "00013b17ad220c46,0.011045855700524682,2.2657309115743063e-06,0.0040477238674169035,4.140574429288222e-07,0.0030133194566428012,0.0001855103048161947\n",
      "00017563c3f7919a,0.0013935085373870495,2.418637613059557e-06,0.0011317354367468948,1.9164796559192376e-06,0.00024061190759940834,1.1087338553423825e-05\n",
      "00017695ad8997eb,0.01934322818588369,1.6867080823994408e-06,0.019195520387795605,2.8038070393344008e-05,0.011620431396047388,0.00013318998337354918\n",
      "0001ea8717f6de06,0.0005090831743457273,3.4166044337475747e-07,0.0019799700070688613,1.1219290212100511e-05,0.002371109944795833,1.4832475165249281e-05\n",
      "00024115d4cbde0f,0.0009483229672622675,3.6385004154584955e-08,0.008461235882497328,2.3291952838965204e-06,0.0006237247899041337,1.399510102919284e-06\n",
      "000247e83dcc1211,0.5718015613401016,7.971241654560273e-06,0.1486269316873378,0.004011346445633238,0.2857707710084653,0.017863346805933326\n",
      "00025358d4737918,0.008137999212009769,2.2066847020375058e-07,0.0037351243932090264,9.692268022366377e-07,0.00039520881888565083,2.740781261062015e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='head sub_MChain_MLP.csv', returncode=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df.to_csv(SUB_CSV_NAME, index=False)\n",
    "subprocess.run(cmd1, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21.3M/21.3M [00:14<00:00, 1.57MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Toxic Comment Classification Challenge"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f sub_MChain_MLP.csv -m \"Manual Chain 5000\"', returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(cmd2, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
