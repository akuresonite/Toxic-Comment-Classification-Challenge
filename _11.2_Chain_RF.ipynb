{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu cores found: 64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "from helper_functions import *\n",
    "print(\"Cpu cores found:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/train.csv.zip\")\n",
    "test_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/test.csv.zip\")\n",
    "test_labels_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/test_labels.csv.zip\")\n",
    "sample_sub_fname = Path(\"/home/23m1521/datasets/jigsaw-toxic-comment/sample_submission.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_full = pd.read_csv(train_fname)\n",
    "# test_df = pd.read_csv(test_fname)\n",
    "# test_labels = pd.read_csv(test_labels_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df = pd.read_csv(sample_sub_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_classes = list(sample_sub_df.columns[1:])\n",
    "comments_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP1(text):\n",
    "    text_tok = word_tokenize(text)\n",
    "    \n",
    "    eng_stopwords = stopwords.words('english')\n",
    "    text_stp = [word for word in text_tok if (word.lower() not in eng_stopwords) and word.isalpha()]\n",
    "    \n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    text_stm = [stemmer.stem(word) for word in text_stp]\n",
    "    return text_stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000 # or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# eng_stopwords = stopwords.words('english')\n",
    "\n",
    "# vectorizer = TfidfVectorizer(lowercase=True, \n",
    "#                                tokenizer=NLP1,\n",
    "#                                stop_words=eng_stopwords,\n",
    "#                                ngram_range=(1,2),\n",
    "#                                max_features=max_features).fit(train_df_full.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, val_df = train_test_split(train_df_full, test_size=0.3, random_state=43)\n",
    "# train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_full = vectorizer.transform(train_df.comment_text)\n",
    "# x_val_full = vectorizer.transform(val_df.comment_text)\n",
    "# x_test_full = vectorizer.transform(test_df.comment_text)\n",
    "\n",
    "# y_train_full = train_df[comments_classes].to_numpy()\n",
    "# y_val_full = val_df[comments_classes].to_numpy()\n",
    "\n",
    "# x_train_full.shape, y_train_full.shape, x_val_full.shape, y_val_full.shape, x_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(x_train_full, f'x_train_full_{max_features}.joblib')\n",
    "# joblib.dump(x_val_full, f'x_val_full_{max_features}.joblib')\n",
    "# joblib.dump(x_test_full, f'x_test_full_{max_features}.joblib')\n",
    "\n",
    "# joblib.dump(y_train_full, f'y_train_full_{max_features}.joblib')\n",
    "# joblib.dump(y_val_full, f'y_val_full_{max_features}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((111699, 5000), (111699, 6), (47872, 5000), (47872, 6), (153164, 5000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full = joblib.load(f'x_train_full_{max_features}.joblib')\n",
    "x_val_full = joblib.load(f'x_val_full_{max_features}.joblib')\n",
    "x_test_full = joblib.load(f'x_test_full_{max_features}.joblib')\n",
    "\n",
    "y_train_full = joblib.load(f'y_train_full_{max_features}.joblib')\n",
    "y_val_full = joblib.load(f'y_val_full_{max_features}.joblib')\n",
    "\n",
    "x_train_full.shape, y_train_full.shape, x_val_full.shape, y_val_full.shape, x_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_MChain_RF.csv\n",
      "head sub_MChain_RF.csv\n",
      "kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f sub_MChain_RF.csv -m \"Manual Chain 5000\"\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MChain_RF'\n",
    "SUB_CSV_NAME = f\"sub_{MODEL_NAME}.csv\"\n",
    "SUB_CSV_MSG = f\"Manual Chain\"\n",
    "\n",
    "cmd1 = f\"head {SUB_CSV_NAME}\"\n",
    "cmd2 = f'kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f {SUB_CSV_NAME} -m \"{SUB_CSV_MSG} {max_features}\"'\n",
    "print(SUB_CSV_NAME)\n",
    "print(cmd1)\n",
    "print(cmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 0 toxic ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_RF model on toxic column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   53.5s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9929536710561752\n",
      "Val ROC: 0.8247974392154022\n",
      "Train Acc: 0.9984332894654384\n",
      "Val Acc: 0.9558405748663101\n",
      "test_prob: (153164, 2)\n",
      "******************** 1 severe_toxic ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_RF model on severe_toxic column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   23.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9736764221888249\n",
      "Val ROC: 0.5402599463943141\n",
      "Train Acc: 0.9994180789443057\n",
      "Val Acc: 0.9897852606951871\n",
      "test_prob: (153164, 2)\n",
      "******************** 2 obscene ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_RF model on obscene column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   33.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9932734027167286\n",
      "Val ROC: 0.8694819336429046\n",
      "Train Acc: 0.999059973679263\n",
      "Val Acc: 0.9791945187165776\n",
      "test_prob: (153164, 2)\n",
      "******************** 3 threat ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_RF model on threat column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9848439952687993\n",
      "Val ROC: 0.5201759780902351\n",
      "Train Acc: 0.9999015210521133\n",
      "Val Acc: 0.9968457553475936\n",
      "test_prob: (153164, 2)\n",
      "******************** 4 insult ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_RF model on insult column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   37.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9912659233147867\n",
      "Val ROC: 0.8083237218093879\n",
      "Train Acc: 0.9986212947295857\n",
      "Val Acc: 0.9683531082887701\n",
      "test_prob: (153164, 2)\n",
      "******************** 5 identity_hate ********************\n",
      "x_train: (111699, 5006)\n",
      "x_val: (47872, 5006)\n",
      "x_test: (153164, 5006)\n",
      "y_train: (111699,)\n",
      "y_val: (47872,)\n",
      "Fitting MChain_RF model on identity_hate column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   24.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 322 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=64)]: Done 672 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9836730659623435\n",
      "Val ROC: 0.6268368171555905\n",
      "Train Acc: 0.9996597999982094\n",
      "Val Acc: 0.9931066176470589\n",
      "test_prob: (153164, 2)\n",
      "test_probs: (2, 153164, 6)\n",
      "CPU times: user 3h 35min 45s, sys: 10.8 s, total: 3h 35min 56s\n",
      "Wall time: 3min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=None, random_state=42,verbose=1, n_jobs=-1)\n",
    "x_train = lil_matrix(np.concatenate((x_train_full.toarray(), np.zeros_like(y_train_full)), axis=1))\n",
    "x_val = lil_matrix(np.concatenate((x_val_full.toarray(), np.zeros_like(y_val_full)), axis=1))\n",
    "x_test = lil_matrix(np.concatenate((x_test_full.toarray(), np.zeros((x_test_full.shape[0],6))), axis=1))\n",
    "test_probs = []\n",
    "\n",
    "for i, class_ in enumerate(comments_classes):\n",
    "    print('*'*20, i, class_, '*'*20)\n",
    "    \n",
    "    y_train, y_val = y_train_full[:,i], y_val_full[:,i]\n",
    "    print(\"x_train:\", x_train.shape)\n",
    "    print(\"x_val:\", x_val.shape)\n",
    "    print(\"x_test:\", x_test.shape)\n",
    "    print(\"y_train:\", y_train.shape)\n",
    "    print(\"y_val:\", y_val.shape)\n",
    "    \n",
    "    print(f'Fitting {MODEL_NAME} model on {class_} column...')\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(x_train)\n",
    "    val_pred = clf.predict(x_val)\n",
    "    test_pred = clf.predict(x_test)\n",
    "    test_prob = clf.predict_proba(x_test)\n",
    "    print(\"Train ROC:\", roc_auc_score(y_train,train_pred))\n",
    "    print(\"Val ROC:\", roc_auc_score(y_val,val_pred))\n",
    "    print(\"Train Acc:\", accuracy_score(y_train, train_pred))\n",
    "    print(\"Val Acc:\", accuracy_score(y_val, val_pred))\n",
    "    \n",
    "    x_train[:,5000+i] = train_pred\n",
    "    x_val[:,5000+i] = val_pred\n",
    "    x_test[:,5000+i] = test_pred\n",
    "    print('test_prob:', test_prob.shape)\n",
    "    test_probs.append(test_prob)\n",
    "    \n",
    "test_probs = np.array(test_probs).T\n",
    "print(\"test_probs:\", test_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 153164, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.loc[:, comments_classes] = test_probs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.262967</td>\n",
       "      <td>0.825667</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.139717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.642183</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.643917</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.455475</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene  threat    insult  \\\n",
       "0       00001cee341fdb12  0.899000      0.262967  0.825667   0.029  0.787500   \n",
       "1       0000247867823ef7  0.001000      0.000000  0.000000   0.000  0.004000   \n",
       "2       00013b17ad220c46  0.000000      0.000000  0.000000   0.000  0.000000   \n",
       "3       00017563c3f7919a  0.001000      0.000000  0.000000   0.000  0.000000   \n",
       "4       00017695ad8997eb  0.002000      0.000000  0.001000   0.000  0.000000   \n",
       "...                  ...       ...           ...       ...     ...       ...   \n",
       "153159  fffcd0960ee309b5  0.026000      0.000000  0.006000   0.000  0.000000   \n",
       "153160  fffd7a9a6eb32c16  0.139717      0.000000  0.003000   0.000  0.005000   \n",
       "153161  fffda9e8d6fafa9e  0.004000      0.000000  0.001000   0.000  0.000000   \n",
       "153162  fffe8f1340a79fc2  0.018000      0.000000  0.000000   0.000  0.001000   \n",
       "153163  ffffce3fb183ee80  0.642183      0.002000  0.643917   0.003  0.455475   \n",
       "\n",
       "        identity_hate  \n",
       "0               0.197  \n",
       "1               0.000  \n",
       "2               0.000  \n",
       "3               0.001  \n",
       "4               0.017  \n",
       "...               ...  \n",
       "153159          0.001  \n",
       "153160          0.044  \n",
       "153161          0.000  \n",
       "153162          0.000  \n",
       "153163          0.008  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
      "00001cee341fdb12,0.899,0.2629666666666667,0.8256666666666668,0.029,0.7875,0.197\n",
      "0000247867823ef7,0.001,0.0,0.0,0.0,0.004,0.0\n",
      "00013b17ad220c46,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "00017563c3f7919a,0.001,0.0,0.0,0.0,0.0,0.001\n",
      "00017695ad8997eb,0.002,0.0,0.001,0.0,0.0,0.017\n",
      "0001ea8717f6de06,0.007,0.0,0.002,0.0,0.0,0.0\n",
      "00024115d4cbde0f,0.001,0.0,0.0,0.0,0.0,0.0\n",
      "000247e83dcc1211,0.178,0.0,0.0020886319845857416,0.0,0.0013371453071819017,1.879327747700691e-05\n",
      "00025358d4737918,0.1753,0.001,0.001,0.001,0.015,0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='head sub_MChain_RF.csv', returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df.to_csv(SUB_CSV_NAME, index=False)\n",
    "subprocess.run(cmd1, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.04M/9.04M [00:03<00:00, 2.54MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Toxic Comment Classification Challenge"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f sub_MChain_RF.csv -m \"Manual Chain 5000\"', returncode=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(cmd2, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
